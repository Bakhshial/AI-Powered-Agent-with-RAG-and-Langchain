{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ### Step 1: Install Required Libraries\n",
        "!pip install -q langchain faiss-cpu tiktoken\n",
        "!pip install -q langchain_huggingface\n",
        "!pip install -q langchain_community\n",
        "!pip install -q langchain_google_community\n",
        "!pip install -q pypdf\n",
        "!pip install -q langchain_groq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X0Xx3hNeLINO",
        "outputId": "af640c34-442a-4ade-d76e-c1000ee8b7f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/67.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.5/27.5 MB\u001b[0m \u001b[31m80.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.1/611.1 kB\u001b[0m \u001b[31m43.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m89.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m64.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.6/278.6 kB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m87.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m101.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.8/55.8 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.8/70.8 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.2/73.2 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m101.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m452.6/452.6 kB\u001b[0m \u001b[31m36.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.17.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.29.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m41.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m58.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m412.2/412.2 kB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.6/49.6 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.4/84.4 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Step 2: Import Necessary Modules\n",
        "import os\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from langchain.chains import RetrievalQA, create_retrieval_chain\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.tools import Tool\n",
        "from langchain.agents import create_react_agent, AgentExecutor\n",
        "from langchain.llms import HuggingFaceHub\n",
        "from langchain.prompts.prompt import PromptTemplate\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "from langchain_community.utilities import GoogleSearchAPIWrapper\n",
        "from langchain.chains.conversation.memory import ConversationBufferWindowMemory\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain_community.utilities import GoogleSerperAPIWrapper"
      ],
      "metadata": {
        "id": "SlG6t3IPLKap"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Step 3: Configure API Keys and Environment Variables\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"GROQ_API_KEY\"] = userdata.get(\"GROQ_API_KEY\")\n",
        "os.environ[\"SERPER_API_KEY\"] = userdata.get(\"SERPER_API_KEY\")\n",
        "\n",
        "# Check if all keys are loaded correctly\n",
        "if not all([\n",
        "    os.getenv(\"GROQ_API_KEY\"),\n",
        "    os.getenv(\"SERPER_API_KEY\")\n",
        "]):\n",
        "    raise ValueError(\"One or more API keys are missing. Ensure keys are added to Colab userdata.\")"
      ],
      "metadata": {
        "id": "FGTRvdn1Lz54"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Step 4: Define RAG Prompt Template\n",
        "system_prompt = (\n",
        "    \"You are an assistant for question-answering tasks. \"\n",
        "    \"Use the following pieces of retrieved context to answer \"\n",
        "    \"the question. If you don't know the answer, say that you \"\n",
        "    \"don't know. Use three sentences maximum and keep the \"\n",
        "    \"answer concise.\\n\\n\"\n",
        "    \"{context}\"\n",
        ")\n",
        "\n",
        "rag_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", system_prompt),\n",
        "    (\"human\", \"{input}\"),\n",
        "])"
      ],
      "metadata": {
        "id": "B39ek2zyL0Cv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to process a PDF file and extract text\n",
        "def process_pdf(pdf_path):\n",
        "    try:\n",
        "        loader = PyPDFLoader(pdf_path)  # Use LangChain's PyPDFLoader\n",
        "        documents = loader.load()  # Load the PDF into documents\n",
        "        return documents  # Return list of documents\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to extract text from PDF {pdf_path}: {e}\")\n",
        "        return []\n",
        "\n",
        "# Function to process a TXT file and extract text\n",
        "def process_txt(txt_path):\n",
        "    try:\n",
        "        loader = TextLoader(txt_path)  # Use LangChain's TextLoader\n",
        "        documents = loader.load()  # Load the TXT file into documents\n",
        "        return documents  # Return list of documents\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to extract text from TXT file {txt_path}: {e}\")\n",
        "        return []\n",
        "\n",
        "# Function to process files and prepare vector store\n",
        "def process_files_and_create_retriever(folder_path):\n",
        "    import os\n",
        "\n",
        "    all_documents = []  # List to store all documents\n",
        "\n",
        "    for root, dirs, files in os.walk(folder_path):  # Traverse all files in the folder\n",
        "        for file in files:\n",
        "            file_path = os.path.join(root, file)  # Full path of the file\n",
        "            ext = file.split(\".\")[-1].lower()  # Get file extension\n",
        "\n",
        "            if ext == \"pdf\":\n",
        "                all_documents.extend(process_pdf(file_path))\n",
        "            elif ext == \"txt\":\n",
        "                all_documents.extend(process_txt(file_path))\n",
        "            else:\n",
        "                print(f\"Unsupported file type for {file}\")\n",
        "\n",
        "    # Split documents into chunks\n",
        "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
        "    docs = text_splitter.split_documents(all_documents)\n",
        "\n",
        "    # Create vector store with HuggingFace embeddings\n",
        "    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "    vector_store = FAISS.from_documents(docs, embeddings)\n",
        "\n",
        "    # Create retriever\n",
        "    retriever = vector_store.as_retriever(search_type=\"similarity\", search_k=3)\n",
        "    return retriever"
      ],
      "metadata": {
        "id": "XhSroS2sqWqE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.schema import Document\n",
        "### Step 6: Web Scraping Function\n",
        "def scrape_website(url):\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status()\n",
        "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
        "        return soup.get_text()\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        return f\"Error scraping {url}: {e}\"\n",
        "\n",
        "\n",
        "\n",
        "### Step 7: Prepare Web Data for Retrieval\n",
        "# Define URLs to scrape\n",
        "urls = [\n",
        "    \"https://medium.com/@jagadeesan.ganesh/agentic-rag-with-langchain-revolutionizing-ai-with-dynamic-decision-making-ff1dee6df4ca\",\n",
        "    \"https://medium.com/the-ai-forum/implementing-agentic-rag-using-langchain-b22af7f6a3b5\",\n",
        "    \"https://www.bbc.com/news/technology\",\n",
        "    \"https://www.dawn.com/tech\"\n",
        "]\n",
        "\n",
        "web_data_list = []\n",
        "for url in urls:\n",
        "    print(f\"Scraping: {url}\")\n",
        "    web_data = scrape_website(url)\n",
        "    web_data_list.append(web_data)\n",
        "\n",
        "combined_web_data = \"\\n\".join(web_data_list)\n",
        "\n",
        "# Convert scraped content into Document objects\n",
        "web_document = Document(page_content=combined_web_data, metadata={\"source\": \"web\"})\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
        "docs = text_splitter.split_documents([web_document])\n",
        "\n",
        "# Create vector store for web data\n",
        "web_vector_store = FAISS.from_documents(\n",
        "    docs, HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        ")\n",
        "retriever = web_vector_store.as_retriever(search_type=\"similarity\", search_k=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xlC2zlo_L7Y3",
        "outputId": "eb0c3a0a-aaab-4eb6-e511-9817ccbefc92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scraping: https://medium.com/@jagadeesan.ganesh/agentic-rag-with-langchain-revolutionizing-ai-with-dynamic-decision-making-ff1dee6df4ca\n",
            "Scraping: https://medium.com/the-ai-forum/implementing-agentic-rag-using-langchain-b22af7f6a3b5\n",
            "Scraping: https://www.bbc.com/news/technology\n",
            "Scraping: https://www.dawn.com/tech\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Step 8: Initialize ChatGroq Model\n",
        "chat_model = ChatGroq(\n",
        "    temperature=0,\n",
        "    groq_api_key=os.getenv(\"GROQ_API_KEY\"),\n",
        "    model=\"llama3-8b-8192\"\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "### Step 9: Create Retrieval QA Chain\n",
        "question_answer_chain = create_stuff_documents_chain(\n",
        "    llm=chat_model,\n",
        "    prompt=rag_prompt\n",
        ")\n",
        "rag_chain = create_retrieval_chain(retriever, question_answer_chain)"
      ],
      "metadata": {
        "id": "oxwViEoyMaD-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.utilities import GoogleSerperAPIWrapper\n",
        "\n",
        "# Initialize Google search tool\n",
        "search = GoogleSerperAPIWrapper()\n",
        "\n",
        "\n",
        "# Create a new tool for document retrieval from processed PDF and TXT files\n",
        "def file_retriever_tool(query):\n",
        "    retriever = process_files_and_create_retriever(\"/content/drive/MyDrive/Chatbot\")  # Set your folder path here\n",
        "    results = retriever.get_relevant_documents(query)\n",
        "    return \"\\n\".join([doc.page_content for doc in results])\n",
        "\n",
        "# Define tools for the agent\n",
        "tools = [\n",
        "    Tool(\n",
        "        name=\"RAG For Web\",\n",
        "        func=rag_chain.invoke,  # Assuming rag_chain.invoke is the method that handles RAG\n",
        "        description=\"Useful when you're asked Retrieval Augmented Generation (RAG) related questions.\"\n",
        "    ),\n",
        "    Tool(\n",
        "        name=\"Google Search\",\n",
        "        description=\"For answering questions not in the knowledge base, use Google search.\",\n",
        "        func=search.run  # Google search tool function\n",
        "    ),\n",
        "    Tool(\n",
        "        name=\"File Retriever\",\n",
        "        description=\"Retrieves documents from processed PDFs and TXT files in a folder.\",\n",
        "        func=file_retriever_tool  # Function to retrieve documents from folder\n",
        "    ),\n",
        "]"
      ],
      "metadata": {
        "id": "zmBajQbHMaGK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts.prompt import PromptTemplate\n",
        "\n",
        "# Updated character prompt\n",
        "character_prompt = \"\"\"Answer the following questions as best you can. You have access to the following tools:\n",
        "{tools}\n",
        "\n",
        "For any questions requiring tools, you should first search the provided knowledge base. If you don't find relevant information from provided knowledge base, then use Google search to find related information.\n",
        "\n",
        "To use a tool, you MUST use the following format:\n",
        "1. Thought: Do I need to use a tool? Yes\n",
        "2. Action: the action to take, should be one of [{tool_names}]\n",
        "3. Action Input: the input to the action\n",
        "4. Observation: the result of the action\n",
        "\n",
        "When you have a response to say to the Human, or if you do not need to use a tool, you MUST use the following format:\n",
        "1. Thought: Do I need to use a tool? No\n",
        "2. Final Answer: [your response here]\n",
        "\n",
        "It's very important to always include the 'Thought' before any 'Action' or 'Final Answer'. Ensure your output strictly follows the formats above.\n",
        "\n",
        "Begin!\n",
        "\n",
        "Previous conversation history:\n",
        "{chat_history}\n",
        "\n",
        "Question: {input}\n",
        "Thought: {agent_scratchpad}\n",
        "\"\"\"\n",
        "\n",
        "# Initialize the prompt template\n",
        "prompt = PromptTemplate.from_template(character_prompt)\n",
        "\n",
        "# Fix for missing variables\n",
        "agent = create_react_agent(\n",
        "    llm=chat_model,  # LLM instance\n",
        "    tools=tools,     # List of tools\n",
        "    prompt=prompt    # Corrected prompt template\n",
        ")\n",
        "\n",
        "# Ensure agent scratchpad is included dynamically\n",
        "memory = ConversationBufferWindowMemory(\n",
        "    memory_key='chat_history',\n",
        "    k=5,\n",
        "    return_messages=True,\n",
        "    output_key=\"output\"\n",
        ")\n",
        "\n",
        "agent_chain = AgentExecutor(\n",
        "    agent=agent,\n",
        "    tools=tools,\n",
        "    memory=memory,\n",
        "    max_iterations=5,\n",
        "    handle_parsing_errors=True,\n",
        "    verbose=True,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zbPWM-KEMaJ1",
        "outputId": "566b3572-668f-4c19-e76c-62cbcf3ccd40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-23-85aeb8b96b4d>:41: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
            "  memory = ConversationBufferWindowMemory(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the input keys expected by the chain\n",
        "expected_input_key = \"input\"  # This should match the variable defined in your PromptTemplate\n",
        "\n",
        "# Example invocation with correct input\n",
        "response = agent_chain.invoke({expected_input_key: \"can you give me news of today?\"})\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJEWW85DMsV3",
        "outputId": "8b177390-a588-46ab-a9fd-eb2be8c11ecd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? Yes\n",
            "Action: Google Search\n",
            "Action Input: \"latest news\"\u001b[0m\u001b[33;1m\u001b[1;3mView the latest news and breaking news today for U.S., world, weather, entertainment, politics and health at CNN.com. Breaking News, Latest News and Current News from FOXNews.com. Breaking news and video. Latest Current News: U.S., World, Entertainment, Health, Business, ... Read full articles, watch videos, browse thousands of titles and more on the \"Home page\" topic with Google News. Go to NBCNews.com for breaking news, videos, and the latest top stories in world news, business, politics, health and pop culture. Your trusted source for breaking news, analysis, exclusive interviews, headlines, and videos at ABCNews.com. Read the latest headlines, breaking news, and videos at APNews.com, the definitive source for independent journalism from every corner of the globe. The latest transcripts, proclamations, executive orders, and press releases ... News. Remarks · Briefings & Statements · Presidential Actions · articles ... CBS News offers breaking news coverage of today's top headlines. Stay informed on the biggest new stories with our balanced, trustworthy reporting. Find latest news from every corner of the globe at Reuters.com, your online source for breaking international news coverage. Visit BBC News for up-to-the-minute news, breaking news, video, audio and feature stories. BBC News provides trusted World and UK news as well as local and ...\u001b[0m\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? No\n",
            "\n",
            "Final Answer: You can visit the websites mentioned in the observation, such as CNN.com, FOXNews.com, Google News, NBCNews.com, ABCNews.com, APNews.com, CBS News, and Reuters.com, to get the latest news of today. You can also visit BBC News for up-to-the-minute news and breaking news.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "{'input': 'What is can you give me news of today?', 'chat_history': [], 'output': 'You can visit the websites mentioned in the observation, such as CNN.com, FOXNews.com, Google News, NBCNews.com, ABCNews.com, APNews.com, CBS News, and Reuters.com, to get the latest news of today. You can also visit BBC News for up-to-the-minute news and breaking news.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the input keys expected by the chain\n",
        "expected_input_key = \"input\"  # This should match the variable defined in your PromptTemplate\n",
        "\n",
        "# Example invocation with correct input\n",
        "response = agent_chain.invoke({expected_input_key: \"can you give weather of Karachi today do google search?\"})\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p7FIqagP56Vo",
        "outputId": "89c05134-d277-42d5-c2fd-95157839fd04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? Yes\n",
            "Action: Google Search\n",
            "Action Input: \"weather in Karachi today\"\u001b[0m\u001b[33;1m\u001b[1;3m73°F\u001b[0m\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? No\n",
            "Final Answer: The weather in Karachi today is 23°C.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "{'input': 'can you give weather of Karachi today do google search?', 'chat_history': [HumanMessage(content='What is can you give me news of today?', additional_kwargs={}, response_metadata={}), AIMessage(content='You can visit the websites mentioned in the observation, such as CNN.com, FOXNews.com, Google News, NBCNews.com, ABCNews.com, APNews.com, CBS News, and Reuters.com, to get the latest news of today. You can also visit BBC News for up-to-the-minute news and breaking news.', additional_kwargs={}, response_metadata={}), HumanMessage(content='can you give weather of Karachi today?', additional_kwargs={}, response_metadata={}), AIMessage(content='The weather in Karachi today is 73°F.', additional_kwargs={}, response_metadata={}), HumanMessage(content='can you give weather of Karachi today in celceus?', additional_kwargs={}, response_metadata={}), AIMessage(content='The weather in Karachi today is 23°C.', additional_kwargs={}, response_metadata={}), HumanMessage(content='can you give weather of Karachi today?', additional_kwargs={}, response_metadata={}), AIMessage(content='The weather in Karachi today is 23°C.', additional_kwargs={}, response_metadata={})], 'output': 'The weather in Karachi today is 23°C.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "svksiIYbt5dP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Reference:**\n",
        "\n",
        "https://peaceful0907.medium.com/build-your-customized-chatbot-with-rag-and-langchain-agent-0eae1923702e\n",
        "\n",
        "https://python.langchain.com/docs/integrations/tools/google_serper/"
      ],
      "metadata": {
        "id": "34JN-m-ZxwCu"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KpBJU9XKxymM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}